{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5c74dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d57b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import re\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import yaml\n",
    "from yaml import dump\n",
    "import uuid\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194a5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2392ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c4f54",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172d8a5",
   "metadata": {},
   "source": [
    "#### initialize all required valiables, prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042f2e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(company, period):\n",
    "\n",
    "    train_end = datetime(2023, 12, 31)\n",
    "    test_start = datetime(2024, 1, 1)\n",
    "    test_end = datetime(2024, 2, 8)\n",
    "    \n",
    "    train_features_set = [\n",
    "        ['close_lag_1', 'volume_lag_1']\n",
    "    ]\n",
    "\n",
    "    \n",
    "    date_parse = lambda dates: pd.to_datetime(dates)\n",
    "    path = f\"/diploma_info/datalake/raw_data/{company}_{period}.csv\"\n",
    "    \n",
    "    full_set = pd.read_csv(\n",
    "        path,\n",
    "        parse_dates=[\"Date\"],\n",
    "        date_parser=date_parse,\n",
    "        index_col=[\"Date\"],\n",
    "    )\n",
    "    full_set.index.name = 'date'\n",
    "    full_set.columns = [c.lower() for c in full_set.columns]\n",
    "    \n",
    "    full_set = create_target_value(full_set)\n",
    "    full_set = create_new_features(full_set, test_end)\n",
    "\n",
    "    full_set = full_set.fillna(0)\n",
    "    \n",
    "    \n",
    "    test_start = datetime(full_set.loc[test_start:].index[0].year, full_set.loc[test_start:].index[0].month, full_set.loc[test_start:].index[0].day)\n",
    "    train_end = datetime(full_set.loc[:train_end].index[-1].year, full_set.loc[:train_end].index[-1].month, full_set.loc[:train_end].index[-1].day)\n",
    "    \n",
    "    \n",
    "    return full_set, train_end, test_start, test_end, train_features_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d41c580a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def create_target_value(df):\n",
    "\n",
    "    growth = [0]\n",
    "    diff_value = [0]\n",
    "\n",
    "\n",
    "    for k in range(1, df.shape[0]):\n",
    "        diff_value.append(df.iloc[k][\"close\"] - df.iloc[k-1][\"close\"])\n",
    "        if diff_value[-1] > 0:\n",
    "            growth.append(1)\n",
    "        else:\n",
    "            growth.append(0)\n",
    "\n",
    "    df['diff_value'] = diff_value\n",
    "    df['growth'] = growth\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b4fbfae",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def create_new_features(df, test_end):\n",
    "    \n",
    "    df['year'] = df.index.year\n",
    "    df['month'] = df.index.month\n",
    "    df['day'] = df.index.day\n",
    "    df['day_of_week'] = df.index.weekday\n",
    "    df['week_of_year'] = (df.index.isocalendar()['week']).astype('int')\n",
    "    df['close_lag_1'] = df['close'].shift(1).bfill()\n",
    "    df['volume_lag_1'] = df['volume'].shift(1).bfill()\n",
    "\n",
    "    for window in [3, 5, 7]:\n",
    "        close_agg = pd.DataFrame(round(df['close'].rolling(window=window, closed='left').agg(\n",
    "            ('max', 'min', 'mean')\n",
    "        )))\n",
    "        close_agg.columns = [f'close_max_{window}_days', f'close_min_{window}_days', f'close_mean_{window}_days']\n",
    "        day_mean = close_agg.reset_index()[['date', f'close_max_{window}_days', f'close_min_{window}_days', f'close_mean_{window}_days']]\n",
    "\n",
    "        df = df.reset_index().merge(day_mean, on='date').set_index(\"date\")\n",
    "        df = df.loc[:test_end.strftime(\"%Y%m%d\"),]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01393351",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def define_parameters(company, period, train_end, test_start, test_end, train_features_set, forecast_steps, models_dict, problem):\n",
    "    \n",
    "    list_of_configs = []\n",
    "    \n",
    "    model = None\n",
    "    \n",
    "#     for duration in [90, 240]:\n",
    "    for md in models_dict.values():\n",
    "\n",
    "        if md == 'knear_neighbors':\n",
    "            model = KNeighborsClassifier(n_jobs=-1)\n",
    "        else:\n",
    "            print('Unknown model')\n",
    "\n",
    "        for train_features in train_features_set:\n",
    "            config = {\n",
    "                'unique_uuid': str(uuid.uuid1()),\n",
    "#                     'train_start': datetime(2020, 1, 1),\n",
    "                'train_end': train_end,\n",
    "                'test_start': test_start,\n",
    "                'test_end': test_end,\n",
    "#                     'duration_training_history': duration,\n",
    "                'target_column': 'growth',\n",
    "                'train_features': train_features,\n",
    "                'path_to_result': f'/diploma_info/datalake/',\n",
    "                'forecast_periods': forecast_steps,\n",
    "#                 'hour_mean_value': 5,\n",
    "                'model_name': md,\n",
    "                'model': model,\n",
    "                'forecast_frequency': period.lower(),\n",
    "                'company': company.lower(),\n",
    "                'model_hyperparameters': model.get_params(),\n",
    "                'problem': problem\n",
    "            }\n",
    "\n",
    "            list_of_configs.append(config.copy())\n",
    "    \n",
    "    return list_of_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de80c2e",
   "metadata": {},
   "source": [
    "#### functions used in wfv service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4016f075",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def data(day, X_full_set, y_full_set, train_start, config, forecast_steps):\n",
    "\n",
    "\n",
    "    X_train = X_full_set.loc[train_start:config[\"train_end\"]]\n",
    "    X_test = X_full_set.loc[config[\"test_start\"]+timedelta(days=day):\n",
    "                    config[\"test_start\"]+timedelta(days=day+forecast_steps)]\n",
    "    y_train = y_full_set.loc[train_start:config[\"train_end\"]]\n",
    "    y_test = y_full_set.loc[config[\"test_start\"]+timedelta(days=day):\n",
    "                    config[\"test_start\"]+timedelta(days=day+forecast_steps)]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e1c8fa3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def standardize_mean_values(day, df_test, df_train, config):\n",
    "    \n",
    "    agg_cols = ['close_lag_1', 'volume_lag_1'] + [col for col in config['train_features'] if \"close_m\" in col]\n",
    "    \n",
    "    for agg in agg_cols:\n",
    "        if agg in df_test.columns:\n",
    "            try:\n",
    "                num = df_test.loc[config[\"test_start\"]+timedelta(days=day), agg]\n",
    "\n",
    "            except KeyError as e:\n",
    "                num = df_train[agg].iloc[-1]\n",
    "\n",
    "            finally:\n",
    "\n",
    "                _df = df_test.loc[config[\"test_start\"]+timedelta(days=day):, agg]\n",
    "                _df = _df.replace(_df.values, num)\n",
    "\n",
    "#                 print(df_test.loc[config[\"test_start\"]+timedelta(days=day):, agg], _df.values.ravel())\n",
    "\n",
    "                df_test.loc[config[\"test_start\"]:, agg] = _df.values.ravel()\n",
    "    \n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bc649df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions(day, model_name, df_preds, y_pred_df, y_test, config):\n",
    "    \n",
    "    dates = y_test.index\n",
    "    \n",
    "    for date in dates:\n",
    "        step_day = int((date-(config[\"test_start\"]+timedelta(days=day))).days)\n",
    "        df_preds.loc[date.strftime(\"%Y-%m-%d\"), f'd-{step_day}'] = y_pred_df.loc[date.strftime(\"%Y-%m-%d\"), 0]\n",
    "    \n",
    "    return df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf71e08e",
   "metadata": {
    "code_folding": [
     15,
     20
    ]
   },
   "outputs": [],
   "source": [
    "def estimations(day, df_stats, y_pred_df, y_test, config):\n",
    "    \n",
    "    dates = y_test.index\n",
    "    \n",
    "    for date in dates:\n",
    "        step_day = int((date-(config[\"test_start\"]+timedelta(days=day))).days)\n",
    "\n",
    "        try:\n",
    "            pred = y_pred_df.loc[date].values[0]\n",
    "            real = y_test.loc[date].values[0]\n",
    "\n",
    "            err = pred-real\n",
    "\n",
    "            df_stats.loc[date, f'd-{step_day}' + '_is_true'] = 1 if (err == 0) else 0\n",
    "            \n",
    "        except ZeroDivisionError as e:\n",
    "            print(e)\n",
    "\n",
    "            df_stats.loc[date, f'd-{step_day}' + '_is_true'] = 0\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "\n",
    "            df_stats.loc[date, f'd-{step_day}' + '_is_true'] = 0\n",
    "    \n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "664c8058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(forecast_steps, df_preds, config, research_task_uuid, problem):\n",
    "    \n",
    "    for step in range(forecast_steps+1):\n",
    "        try:\n",
    "            pred = df_preds.loc[:, [f'd-{step}']].dropna().sort_index()\n",
    "            pred.index.name = 'date_time'\n",
    "\n",
    "            path_to_files = os.path.join(config['path_to_result'], \"forecast\", problem,\n",
    "                                         config['company'], config['forecast_frequency'], config['model_name'], \n",
    "                                         f\"research_task_{research_task_uuid}\", \n",
    "                                         f\"{config['model_name']}_{config['unique_uuid']}\")\n",
    "            if not os.path.isdir(path_to_files):\n",
    "                os.makedirs(path_to_files)\n",
    "                \n",
    "            file_name = os.path.join(path_to_files, \n",
    "                    f\"forecast_d-{step}_{config['model_name']}.csv\")\n",
    "\n",
    "            pd.DataFrame(pred).to_csv(file_name)\n",
    "\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41fc750",
   "metadata": {},
   "source": [
    "### wfv service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c32598ef",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_wfv(full_set: pd.DataFrame, config: dict, research_task_uuid: str, forecast_steps: int, company: str, models_dict: dict, problem: str):\n",
    "    \n",
    "    X_full_set = full_set.loc[:, config['train_features']]\n",
    "    y_full_set = full_set.loc[:, [config['target_column']]]\n",
    "    \n",
    "    if X_full_set.shape[0] != y_full_set.shape[0]:\n",
    "        common_index = list(set(X_full_set.index) & set(y_full_set.index))\n",
    "        common_index.sort()\n",
    "        X_full_set = X_full_set.loc[common_index, :]\n",
    "        y_full_set = y_full_set.loc[common_index, :]\n",
    "    print(X_full_set.shape, y_full_set.shape)\n",
    "    \n",
    "\n",
    "    df_preds = pd.DataFrame()\n",
    "    df_stats = pd.DataFrame()\n",
    "\n",
    "    count_days = (test_end - test_start).days + 1\n",
    "    \n",
    "    \n",
    "    model_name = config['model_name']\n",
    "    print(model_name)\n",
    "    \n",
    "    model = config['model']\n",
    "\n",
    "    unique_uuid = config['unique_uuid']\n",
    "    \n",
    "    if not os.path.isdir(config['path_to_result']):\n",
    "        os.makedirs(config['path_to_result'])\n",
    "\n",
    "    path_folder_result = os.path.join(config['path_to_result'], \"wf_result\", problem, config['company'], \n",
    "                                      config['forecast_frequency'], model_name,\n",
    "                                      f\"research_task_{research_task_uuid}\")\n",
    "    if not os.path.isdir(path_folder_result):\n",
    "        os.makedirs(path_folder_result)\n",
    "        \n",
    "        \n",
    "\n",
    "    for day in tqdm(range(count_days)):\n",
    "        \n",
    "        train_start = config.get('train_start', None)\n",
    "        if train_start is None:\n",
    "            if config.get('duration_training_history', None) is None:\n",
    "                train_start = X_full_set.index[0]\n",
    "                config['train_start'] = datetime(train_start.year, train_start.month, train_start.day)\n",
    "            else:\n",
    "                train_start = config['train_end'] + timedelta(days=i - config['duration_training_history'])\n",
    "\n",
    "        try:\n",
    "\n",
    "            X_train, X_test, y_train, y_test = data(day, X_full_set, y_full_set, train_start, config, forecast_steps)\n",
    "    #         print(X_train, y_train)\n",
    "            X_test = standardize_mean_values(day, X_test.copy(), X_train, config)\n",
    "    #             print(test_start+timedelta(days=day), 'x_test: ', X_test.head(2))\n",
    "\n",
    "            y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "            y_pred_df = pd.DataFrame(y_pred, index=y_test.index)\n",
    "            df_preds = add_predictions(day, model_name, df_preds, y_pred_df, y_test, config)\n",
    "\n",
    "#             print(df_preds)\n",
    "\n",
    "            df_stats = estimations(day, df_stats, y_pred_df, y_test, config)\n",
    "    #         print('\\n\\n')\n",
    "        \n",
    "\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "\n",
    "    print(\"\\033[1m\\033[34mAccuracy:\", round(abs(df_stats['d-0_is_true'].dropna().sum() / df_stats['d-0_is_true'].dropna().shape[0]) * 100, 2))\n",
    "\n",
    "    write_predictions(forecast_steps, df_preds, config, research_task_uuid, problem)\n",
    "\n",
    "\n",
    "    last_index = df_stats.index[-1]\n",
    "    df_stats.loc[last_index, 'model_hyperparameters'] = str(config['model_hyperparameters'])\n",
    "    df_stats.loc[last_index, 'train_features'] = str(config['train_features'])\n",
    "    \n",
    "    path_to_save_result_csv = os.path.join(path_folder_result, f'{model_name}_{unique_uuid}.csv')\n",
    "    df_stats.round(2).to_csv(path_to_save_result_csv, date_format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    config_to_save = config.copy()\n",
    "    config_to_save.pop('model', None)\n",
    "    with open(os.path.join(path_folder_result, f'{model_name}_{unique_uuid}.yaml'), 'w') as outfile:\n",
    "        dump(config_to_save, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0650674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company: GOOGLE\t period: daily\t train ends: 2023-12-29 00:00:00\t test starts: 2024-01-02 00:00:00\n",
      "\n",
      "knear_neighbors == {'unique_uuid': '0667d6a2-f5dc-11ee-bdc9-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'target_column': 'growth', 'train_features': ['close_lag_1', 'volume_lag_1'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'knear_neighbors', 'model': KNeighborsClassifier(n_jobs=-1), 'forecast_frequency': 'daily', 'company': 'google', 'model_hyperparameters': {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}, 'problem': 'classification'} \n",
      "\n",
      "(4902, 2) (4902, 1)\n",
      "knear_neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mAccuracy: 48.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "companies = [\"GOOGLE\"]\n",
    "time_period = [\"daily\"]\n",
    "\n",
    "problem = 'classification'\n",
    "models_list = ['KNear_Neighbors']\n",
    "models_dict = dict([(\"\".join(re.findall('([A-Z])', k)).lower(), k.lower()) for k in models_list])\n",
    "\n",
    "forecast_steps = 4        # means that forecast will be made on {n} futute periods \n",
    " \n",
    "\n",
    "for company, period in list(itertools.product(companies, time_period)):\n",
    "    \n",
    "    full_set, train_end, test_start, test_end, train_features_set = init(company, period)\n",
    "    print(f'company: {company}\\t period: {period}\\t train ends: {train_end}\\t test starts: {test_start}\\n')\n",
    "    \n",
    "    _research_task_uuid = str(uuid.uuid1())\n",
    "    print(f'_research_task_uuid = {_research_task_uuid}\\n')\n",
    "    \n",
    "    configs = define_parameters(company, period, train_end, test_start, test_end, train_features_set, forecast_steps, models_dict, problem)\n",
    "    print(f'count_configs {len(configs)} \\n')\n",
    "    \n",
    "    for _ in configs:\n",
    "        print(_['model_name'], '==', _, '\\n')\n",
    "        \n",
    "        run_wfv(full_set, _, _research_task_uuid, forecast_steps, company, models_dict, problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7668b962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
