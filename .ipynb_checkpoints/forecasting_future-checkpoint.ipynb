{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32614edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55eb4f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import re\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import yaml\n",
    "from yaml import dump\n",
    "import uuid\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58a81476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b48a6c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d811b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908fa4e",
   "metadata": {},
   "source": [
    "## Initialize global variables\n",
    "\n",
    "__here we will set all the variables used in both classification and regression problems__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12ad9a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-05-08 00:00:00')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_parse = lambda dates: pd.to_datetime(dates)\n",
    "    \n",
    "companies = [\"AMAZON\", \"APPLE\", \"GOOGLE\", \"META\", \"NETFLIX\"]\n",
    "time_period = [\"daily\"]\n",
    "\n",
    "full_sets = {}\n",
    "\n",
    "for company, period in itertools.product(companies, time_period):\n",
    "    path = f\"/diploma_info/datalake/processed_data/{company}_{period}.csv\"\n",
    "\n",
    "    full_sets[company.lower()] = pd.read_csv(\n",
    "        path,\n",
    "        parse_dates=[\"date\"],\n",
    "        date_parser=date_parse,\n",
    "        index_col=[\"date\"],\n",
    "    )\n",
    "\n",
    "train_end = full_sets[companies[0].lower()].iloc[-1].name\n",
    "test_start = train_end +timedelta(days=1)\n",
    "test_end = test_start + timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c5f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start = datetime(full_set.loc[test_start:].index[0].year, full_set.loc[test_start:].index[0].month, full_set.loc[test_start:].index[0].day)\n",
    "train_end = datetime(full_set.loc[:train_end].index[-1].year, full_set.loc[:train_end].index[-1].month, full_set.loc[:train_end].index[-1].day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef120e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(day, X_full_set, y_full_set, train_start, config, forecast_steps):\n",
    "\n",
    "    X_train = X_full_set.loc[train_start:config[\"train_end\"]]\n",
    "    X_test = X_full_set.loc[config[\"test_start\"]+timedelta(days=day):\n",
    "                    config[\"test_start\"]+timedelta(days=day+forecast_steps)]\n",
    "    y_train = y_full_set.loc[train_start:config[\"train_end\"]]\n",
    "    y_test = y_full_set.loc[config[\"test_start\"]+timedelta(days=day):\n",
    "                    config[\"test_start\"]+timedelta(days=day+forecast_steps)]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35adc743",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def standardize_mean_values(day, df_test, df_train, full_set, config):\n",
    "    \n",
    "    agg_cols = [col for col in config['train_features'] if col.endswith('_lag_1')] + \\\n",
    "               ['diff_open_value', 'open-prev_close', 'diff_close_value', 'growth_open'] + \\\n",
    "               [col for col in config['train_features'] if \"close_m\" in col]\n",
    "    \n",
    "    for agg in agg_cols:\n",
    "        if agg in df_test.columns:\n",
    "            try:\n",
    "                num = df_test.loc[config[\"test_start\"]+timedelta(days=day), agg]\n",
    "\n",
    "            except KeyError as e:\n",
    "                num = df_train[agg].iloc[-1]\n",
    "\n",
    "            finally:\n",
    "\n",
    "                _df = df_test.loc[config[\"test_start\"]+timedelta(days=day):, agg]\n",
    "                _df = _df.replace(_df.values, num)\n",
    "\n",
    "#                 print(df_test.loc[config[\"test_start\"]+timedelta(days=day):, agg], _df.values.ravel())\n",
    "\n",
    "                df_test.loc[config[\"test_start\"]:, agg] = _df.values.ravel()\n",
    "    \n",
    "    if 'open' in config['train_features']:\n",
    "        \n",
    "        idx_1 = df_test.iloc[1].name\n",
    "        df_test.loc[idx_1, 'open'] = full_set.loc[idx_1, 'new_open']\n",
    "        \n",
    "        for n in range(df_test.loc[idx_1+timedelta(days=1):].shape[0]):\n",
    "            \n",
    "            _date = df_test.loc[idx_1+timedelta(days=1):].iloc[n].name\n",
    "            df_test.loc[_date, 'open'] = full_set.loc[df_test.iloc[1+n].name, 'open'] + full_set.loc[idx_1-timedelta(days=5):idx_1, 'diff_open_value_mean_3_days'].mean()\n",
    "        \n",
    "    \n",
    "    \n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions(day, model_name, df_preds, y_pred_df, y_test, config):\n",
    "    \n",
    "    dates = y_test.index\n",
    "    \n",
    "    for date in dates:\n",
    "        step_day = int((date-(config[\"test_start\"]+timedelta(days=day))).days)\n",
    "        df_preds.loc[date.strftime(\"%Y-%m-%d\"), f'd-{step_day}'] = y_pred_df.loc[date.strftime(\"%Y-%m-%d\"), 0]\n",
    "    \n",
    "    return df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c172b4",
   "metadata": {
    "code_folding": [
     26,
     31
    ]
   },
   "outputs": [],
   "source": [
    "def estimations(day, df_stats, y_pred_df, y_test, config, problem):\n",
    "    \n",
    "    dates = y_test.index\n",
    "    \n",
    "    for date in dates:\n",
    "        step_day = int((date-(config[\"test_start\"]+timedelta(days=day))).days)\n",
    "\n",
    "        try:\n",
    "            pred = y_pred_df.loc[date].values[0]\n",
    "            real = y_test.loc[date].values[0]\n",
    "\n",
    "            if problem == 'regression':\n",
    "                err = abs(pred / real - 1) * 100\n",
    "\n",
    "                df_stats.loc[date, f'd-{step_day}' + '_total_abs_error'] = np.round(abs(pred-real))\n",
    "                df_stats.loc[date, f'd-{step_day}' + '_total_relative_error'] = np.round(abs(pred / real - 1), 4) * 100\n",
    "                df_stats.loc[date, f'd-{step_day}' + '_more_5'] = 1 if (err > 5) else 0\n",
    "                df_stats.loc[date, f'd-{step_day}' + '_more_10'] = 1 if (err > 10) else 0\n",
    "                \n",
    "            \n",
    "            elif problem == 'classification':\n",
    "                err = pred-real\n",
    "\n",
    "                df_stats.loc[date, f'd-{step_day}' + '_is_true'] = 1 if (err == 0) else 0\n",
    "                \n",
    "                \n",
    "        except ZeroDivisionError as e:\n",
    "            print(e)\n",
    "\n",
    "            df_stats.loc[date, :] = 0\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "\n",
    "            df_stats.loc[date, :] = 0\n",
    "            \n",
    "    \n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4aa4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(forecast_steps, df_preds, config, research_task_uuid, problem):\n",
    "    \n",
    "    for step in range(forecast_steps+1):\n",
    "        try:\n",
    "            pred = df_preds.loc[:, [f'd-{step}']].dropna().sort_index()\n",
    "            pred.index.name = 'date_time'\n",
    "\n",
    "            path_to_files = os.path.join(config['path_to_result'], \"forecast\", problem,\n",
    "                                         config['company'], config['forecast_frequency'], config['model_name'], \n",
    "                                         f\"research_task_{research_task_uuid}\", \n",
    "                                         f\"{config['model_name']}_{config['unique_uuid']}\")\n",
    "            if not os.path.isdir(path_to_files):\n",
    "                os.makedirs(path_to_files)\n",
    "                \n",
    "            file_name = os.path.join(path_to_files, \n",
    "                    f\"forecast_d-{step}_{config['model_name']}.csv\")\n",
    "\n",
    "            pd.DataFrame(pred).to_csv(file_name)\n",
    "\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514c68bb",
   "metadata": {},
   "source": [
    "## CLASSIFICATION\n",
    "\n",
    "__forecast whether the price will rise or fall in next several days__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c49d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = 'classification'\n",
    "models_list = ['xgboost', 'lightgbm', 'random_forest', 'knear_neighbors']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a7041e",
   "metadata": {},
   "source": [
    "## REGRESSION\n",
    "\n",
    "__forecast the price itself for next several days__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88621d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = 'regression'\n",
    "models_list = ['xgboost', 'lightgbm', 'random_forest', 'linear_regression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28313b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/diploma_info/datalake/wf_result/regression/amazon/daily\\linear_regression\\research_task_1e38d407-0dc3-11ef-8639-c0e434d84b22\\linear_regression_1e38d412-0dc3-11ef-8dc7-c0e434d84b22.yaml\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'amazon': '1e38d412-0dc3-11ef-8dc7-c0e434d84b22',\n",
    "    'apple': '29753b7f-0dc3-11ef-b287-c0e434d84b22',\n",
    "    'meta': '3d63daab-0dc3-11ef-966d-c0e434d84b22',\n",
    "    'google': '343a246e-0dc3-11ef-9323-c0e434d84b22',\n",
    "    'netflix': '462af9c7-0dc3-11ef-ab57-c0e434d84b22'\n",
    "}\n",
    "\n",
    "paths_to_configs = []\n",
    "configs = []\n",
    "\n",
    "for i in range(len(models.items())):  \n",
    "    comp = list(models.keys())[i]\n",
    "    paths_to_configs += glob(f'/diploma_info/datalake/wf_result/{problem}/{comp}/daily/*/research_task_*/*_{models[comp]}.yaml')\n",
    "\n",
    "print(paths_to_configs[0])\n",
    "    \n",
    "for file in paths_to_configs: \n",
    "    with open(file, 'r') as f:\n",
    "        configs += yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2394dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['company',\n",
       " 'forecast_frequency',\n",
       " 'forecast_periods',\n",
       " 'model_hyperparameters',\n",
       " 'model_name',\n",
       " 'path_to_result',\n",
       " 'problem',\n",
       " 'target_column',\n",
       " 'test_end',\n",
       " 'test_start',\n",
       " 'train_end',\n",
       " 'train_features',\n",
       " 'train_start',\n",
       " 'unique_uuid',\n",
       " 'company',\n",
       " 'forecast_frequency',\n",
       " 'forecast_periods',\n",
       " 'model_hyperparameters',\n",
       " 'model_name',\n",
       " 'path_to_result',\n",
       " 'problem',\n",
       " 'target_column',\n",
       " 'test_end',\n",
       " 'test_start',\n",
       " 'train_end',\n",
       " 'train_features',\n",
       " 'train_start',\n",
       " 'unique_uuid',\n",
       " 'company',\n",
       " 'forecast_frequency',\n",
       " 'forecast_periods',\n",
       " 'model_hyperparameters',\n",
       " 'model_name',\n",
       " 'path_to_result',\n",
       " 'problem',\n",
       " 'target_column',\n",
       " 'test_end',\n",
       " 'test_start',\n",
       " 'train_end',\n",
       " 'train_features',\n",
       " 'train_start',\n",
       " 'unique_uuid',\n",
       " 'company',\n",
       " 'forecast_frequency',\n",
       " 'forecast_periods',\n",
       " 'model_hyperparameters',\n",
       " 'model_name',\n",
       " 'path_to_result',\n",
       " 'problem',\n",
       " 'target_column',\n",
       " 'test_end',\n",
       " 'test_start',\n",
       " 'train_end',\n",
       " 'train_features',\n",
       " 'train_start',\n",
       " 'unique_uuid',\n",
       " 'company',\n",
       " 'forecast_frequency',\n",
       " 'forecast_periods',\n",
       " 'model_hyperparameters',\n",
       " 'model_name',\n",
       " 'path_to_result',\n",
       " 'problem',\n",
       " 'target_column',\n",
       " 'test_end',\n",
       " 'test_start',\n",
       " 'train_end',\n",
       " 'train_features',\n",
       " 'train_start',\n",
       " 'unique_uuid']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
