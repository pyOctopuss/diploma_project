{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5c74dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d57b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import re\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import yaml\n",
    "from yaml import dump\n",
    "import uuid\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194a5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6627bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2392ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4043eb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b7df95",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# companies = [\"AMAZON\", \"APPLE\", \"GOOGLE\", \"META\", \"NETFLIX\"]\n",
    "# time_period = [\"daily\", \"weekly\", \"monthly\"]\n",
    "\n",
    "# path = f\"/diploma_info/datalake/raw_data/{companies[2]}_{time_period[2]}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e717a7fa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# date_parse = lambda dates: pd.to_datetime(dates)\n",
    "\n",
    "# df = pd.read_csv(\n",
    "#     path,\n",
    "#     parse_dates=[\"Date\"],\n",
    "#     date_parser=date_parse,\n",
    "#     index_col=[\"Date\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4002d9dc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# growth = [0]\n",
    "# diff_value = [0]\n",
    "\n",
    "\n",
    "# for k in range(1, df.shape[0]):\n",
    "#     diff_value.append(df.iloc[k][\"Close\"] - df.iloc[k-1][\"Close\"])\n",
    "#     if diff_value[-1] > 0:\n",
    "#         growth.append(1)\n",
    "#     else:\n",
    "#         growth.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa657f5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df['diff_value'] = diff_value\n",
    "# df['growth'] = growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b896891",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63f41236",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df.shape[0]-df.growth.sum(), df.growth.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9b20356",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# start = datetime(2023, 12, 1, 0)\n",
    "# end = datetime(2024, 1, 31, 23)\n",
    "\n",
    "\n",
    "# fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "# text = {\"date\": df.index.date,\n",
    "#         \"open\": df.Open,\n",
    "#         \"high\": df.High,\n",
    "#         \"low\": df.Low,\n",
    "#         \"close\": df.Close,\n",
    "#        }\n",
    "\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=df.index.date,\n",
    "#                          y=df.Close,\n",
    "#                          name='Google',\n",
    "#                          text=round(df.Open, 5),\n",
    "#                          line_color='#000000',\n",
    "#                          hovertemplate=\"Date: %{x}<br>Open: %{text}<br>Close: %{y}\"\n",
    "#                         ),\n",
    "#                secondary_y=False\n",
    "#              )\n",
    "\n",
    "# colors = ['red' if df.iloc[k].growth == 0 else 'green' for k in range(df.shape[0])]\n",
    "\n",
    "# fig.add_trace(go.Bar(x=df.index.date,\n",
    "#                      y=df.diff_value,\n",
    "#                      name='Growth_or_Fall',\n",
    "#                      marker_color=colors,\n",
    "#                      ),\n",
    "#                secondary_y=True\n",
    "#              )\n",
    "\n",
    "\n",
    "# fig.update_layout(title=f'Electricity_consumption', \n",
    "#                   xaxis_tickangle=-45,\n",
    "#                   width=1500,\n",
    "#                   height=800\n",
    "#                  )\n",
    "\n",
    "# fig.update_layout(hovermode=\"x\")\n",
    "# fig.update_xaxes(rangeslider_visible=True)\n",
    "# fig.update_yaxes(title_text=\"Close price value\", secondary_y=False)\n",
    "# fig.update_yaxes(title_text=\"Change\", secondary_y=True)\n",
    "\n",
    "\n",
    "# # fig.write_html()\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e9dd0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99137685",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "908c4f54",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172d8a5",
   "metadata": {},
   "source": [
    "#### initialize all required valiables, prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "042f2e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(company, period):\n",
    "\n",
    "    train_end = datetime(2023, 12, 31)\n",
    "    test_start = datetime(2024, 1, 1)\n",
    "    test_end = datetime(2024, 2, 8)\n",
    "    \n",
    "    train_features_set = [\n",
    "        ['close_mixed', 'volume_mixed'],\n",
    "        ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'],\n",
    "        ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year']\n",
    "    ]\n",
    "\n",
    "    \n",
    "    date_parse = lambda dates: pd.to_datetime(dates)\n",
    "    path = f\"/diploma_info/datalake/processed_data/{company}_{period}.csv\"\n",
    "    \n",
    "    full_set = pd.read_csv(\n",
    "        path,\n",
    "        parse_dates=[\"date\"],\n",
    "        date_parser=date_parse,\n",
    "        index_col=[\"date\"],\n",
    "    )\n",
    "#     full_set.index.name = 'date'\n",
    "#     full_set.columns = [c.lower() for c in full_set.columns]\n",
    "    \n",
    "#     full_set = create_target_value(full_set)\n",
    "#     full_set = create_new_features(full_set, test_end)\n",
    "\n",
    "#     full_set['growth_lag_1', 'growth_lag_2', 'growth_lag_3'] = full_set\n",
    "\n",
    "    full_set = full_set.fillna(0)\n",
    "    \n",
    "    # create _mixed values\n",
    "    full_set['close_mixed'] = full_set['close']\n",
    "    full_set.loc[test_start:, 'close_mixed'] = full_set.loc[test_start:, 'close_lag_1']\n",
    "    full_set['volume_mixed'] = full_set['volume']\n",
    "    full_set.loc[test_start:, 'volume_mixed'] = full_set.loc[test_start:, 'volume_lag_1']\n",
    "    \n",
    "    \n",
    "    test_start = datetime(full_set.loc[test_start:].index[0].year, full_set.loc[test_start:].index[0].month, full_set.loc[test_start:].index[0].day)\n",
    "    train_end = datetime(full_set.loc[:train_end].index[-1].year, full_set.loc[:train_end].index[-1].month, full_set.loc[:train_end].index[-1].day)\n",
    "    \n",
    "    \n",
    "    return full_set, train_end, test_start, test_end, train_features_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d41c580a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def create_target_value(df):\n",
    "\n",
    "    growth = [0]\n",
    "    diff_value = [0]\n",
    "\n",
    "\n",
    "    for k in range(1, df.shape[0]):\n",
    "        diff_value.append(df.iloc[k][\"close\"] - df.iloc[k-1][\"close\"])\n",
    "        if diff_value[-1] > 0:\n",
    "            growth.append(1)\n",
    "        else:\n",
    "            growth.append(0)\n",
    "\n",
    "    df['diff_value'] = diff_value\n",
    "    df['growth'] = growth\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b4fbfae",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def create_new_features(df, test_end):\n",
    "    \n",
    "    df['year'] = df.index.year\n",
    "    df['month'] = df.index.month\n",
    "    df['day'] = df.index.day\n",
    "    df['day_of_week'] = df.index.weekday\n",
    "    df['week_of_year'] = (df.index.isocalendar()['week']).astype('int')\n",
    "    df['close_lag_1'] = df['close'].shift(1).bfill()\n",
    "    df['volume_lag_1'] = df['volume'].shift(1).bfill()\n",
    "\n",
    "    for window in [3, 5, 7]:\n",
    "        close_agg = pd.DataFrame(round(df['close'].rolling(window=window, closed='left').agg(\n",
    "            ('max', 'min', 'mean')\n",
    "        )))\n",
    "        close_agg.columns = [f'close_max_{window}_days', f'close_min_{window}_days', f'close_mean_{window}_days']\n",
    "        day_mean = close_agg.reset_index()[['date', f'close_max_{window}_days', f'close_min_{window}_days', f'close_mean_{window}_days']]\n",
    "\n",
    "        df = df.reset_index().merge(day_mean, on='date').set_index(\"date\")\n",
    "        df = df.loc[:test_end.strftime(\"%Y%m%d\"),]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c42b5f2c",
   "metadata": {
    "code_folding": [
     0,
     70,
     105,
     129
    ]
   },
   "outputs": [],
   "source": [
    "def models_hyperparameter_random_forest(company):\n",
    "\n",
    "    depth_list = []\n",
    "    n_estimators_list = []\n",
    "    \n",
    "    if company == 'amazon':\n",
    "        depth_list = [7]\n",
    "        n_estimators_list = [5000]\n",
    "    elif company == 'apple' or company == 'netflix':\n",
    "        depth_list = [7]\n",
    "        n_estimators_list = [10]\n",
    "    elif company == 'meta':\n",
    "        depth_list = [9]\n",
    "        n_estimators_list = [10]\n",
    "    elif company == 'google':\n",
    "        depth_list = [9]\n",
    "        n_estimators_list = [10, 200]\n",
    "    \n",
    "    hyperparameters_for_model = []\n",
    "    \n",
    "    for depth, n_estimators in itertools.product(depth_list, n_estimators_list):\n",
    "        hyperparameters_for_model.append({\n",
    "                        'n_estimators': n_estimators,\n",
    "                        'n_jobs': -1,\n",
    "                        'random_state': 2,\n",
    "                        'max_depth': depth,\n",
    "            })\n",
    "\n",
    "    return hyperparameters_for_model\n",
    "\n",
    "\n",
    "def models_hyperparameter_xgboost(company):\n",
    "\n",
    "    depth_list = []\n",
    "    n_estimators_list = []\n",
    "    \n",
    "    if company == 'apple' or company == 'google':\n",
    "        depth_list = [7, 9]\n",
    "        n_estimators_list = [10, 200]\n",
    "    elif company == 'amazon':\n",
    "        depth_list = [7]\n",
    "        n_estimators_list = [10]\n",
    "    elif company == 'meta':\n",
    "        depth_list = [7]\n",
    "        n_estimators_list = [5000]\n",
    "    elif company == 'netflix':\n",
    "        depth_list = [9]\n",
    "        n_estimators_list = [200]\n",
    "    \n",
    "    hyperparameters_for_model = []\n",
    "    \n",
    "    for depth, n_estimators in itertools.product(depth_list, n_estimators_list):\n",
    "        hyperparameters_for_model.append({\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'n_jobs': -1,\n",
    "                    'max_depth': depth,\n",
    "                    'eta': 0.3,\n",
    "                    'booster': 'gbtree',\n",
    "                    'objective': 'reg:squarederror',\n",
    "                    'eval_metric': 'rmse',\n",
    "                    'subsample': 1,\n",
    "                    'colsample_bytree': 1,\n",
    "                    'min_child_weight': 1,\n",
    "                    'random_state': 2,\n",
    "            })\n",
    "        \n",
    "    return hyperparameters_for_model\n",
    "\n",
    "\n",
    "def models_hyperparameter_lgbm(company):\n",
    "\n",
    "    depth_list = []\n",
    "    n_estimators_list = []\n",
    "    \n",
    "    if company == 'apple' or company == 'meta':\n",
    "        depth_list = [7, 9]\n",
    "        n_estimators_list = [5000]\n",
    "    elif company == 'amazon':\n",
    "        depth_list = [7]\n",
    "        n_estimators_list = [200]\n",
    "    elif company == 'google':\n",
    "        depth_list = [7, 9]\n",
    "        n_estimators_list = [10]\n",
    "    elif company == 'netflix':\n",
    "        depth_list = [9]\n",
    "        n_estimators_list = [10, 5000]\n",
    "    \n",
    "    hyperparameters_for_model = []\n",
    "    \n",
    "    for depth, n_estimators in itertools.product(depth_list, n_estimators_list):\n",
    "        hyperparameters_for_model.append({\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'n_jobs': -1,\n",
    "                    'max_depth': depth,\n",
    "                    'eta': 0.3,\n",
    "                    'random_state': 2,\n",
    "                    'objective': 'binary',\n",
    "                    'verbosity': -1,\n",
    "                    'metric': 'binary', \n",
    "            })\n",
    "\n",
    "    return hyperparameters_for_model\n",
    "\n",
    "\n",
    "def models_hyperparameter_knn(company):\n",
    "\n",
    "    n_neighbors_list = []\n",
    "    \n",
    "    if company == 'apple'or company == 'netflix':\n",
    "        n_neighbors_list = [3, 50]\n",
    "    elif company == 'amazon':\n",
    "        n_neighbors_list = [50]\n",
    "    elif company == 'meta':\n",
    "        n_neighbors_list = [9]\n",
    "    elif company == 'google':\n",
    "        n_neighbors_list = [3, 5]\n",
    "    \n",
    "    hyperparameters_for_model = []\n",
    "    \n",
    "    for n_neighbors in n_neighbors_list:\n",
    "        hyperparameters_for_model.append({\n",
    "                        'n_neighbors': n_neighbors,\n",
    "                        'n_jobs': -1\n",
    "            })\n",
    "\n",
    "    return hyperparameters_for_model\n",
    "\n",
    "\n",
    "def models_hyperparameter_log(company):\n",
    "\n",
    "    n_estimators_list = [10]\n",
    "    \n",
    "    hyperparameters_for_model = []\n",
    "    \n",
    "    for n_estimators in n_estimators_list:\n",
    "        hyperparameters_for_model.append({\n",
    "                        'max_iter': n_estimators,\n",
    "                        'n_jobs': -1,\n",
    "                        'random_state': 2,\n",
    "                        'solver': 'liblinear'\n",
    "            })\n",
    "\n",
    "    return hyperparameters_for_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01393351",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def define_parameters(company, period, train_end, test_start, test_end, train_features_set, forecast_steps, models_dict, problem):\n",
    "    \n",
    "    list_of_configs = []\n",
    "    \n",
    "    model = None\n",
    "    \n",
    "    for duration in [90]:\n",
    "#     for duration in [90, 120, 180, 240]:\n",
    "#     for train_start in [datetime(2010, 1, 1), datetime(2015, 1, 1), datetime(2020, 1, 1)]:\n",
    "        for md in models_dict.values():\n",
    "            if md == 'random_forest':\n",
    "                hyperparameters_for_model = models_hyperparameter_random_forest(company)\n",
    "            elif md == 'xgboost':\n",
    "                hyperparameters_for_model = models_hyperparameter_xgboost(company)\n",
    "            elif md == 'lightgbm':\n",
    "                hyperparameters_for_model = models_hyperparameter_lgbm(company)\n",
    "            elif md == 'knear_neighbors':\n",
    "                hyperparameters_for_model = models_hyperparameter_knn(company)\n",
    "            elif md == 'logistic_regression':\n",
    "                hyperparameters_for_model = models_hyperparameter_log(company)\n",
    "            else:\n",
    "                print('Unknown model')\n",
    "                return\n",
    "\n",
    "            for hp in hyperparameters_for_model:\n",
    "\n",
    "                if md == 'random_forest':\n",
    "                    model = RandomForestClassifier(**hp)\n",
    "                elif md == 'xgboost':\n",
    "                    model = XGBClassifier(**hp)\n",
    "                elif md == 'lightgbm':\n",
    "                    model = LGBMClassifier(**hp)\n",
    "                elif md == 'knear_neighbors':\n",
    "                    model = KNeighborsClassifier(**hp)\n",
    "                elif md == 'logistic_regression':\n",
    "                    model = LogisticRegression(**hp)\n",
    "                else:\n",
    "                    print('Unknown model')\n",
    "\n",
    "                for train_features in train_features_set:\n",
    "    #                 'volume_lag_1', 'close_max_3_days', 'month'\n",
    "\n",
    "                    if company == 'apple' or company == 'google':\n",
    "                        if 'volume_lag_1' not in train_features and 'month' not in train_features:\n",
    "                            continue\n",
    "                    elif company == 'amazon':\n",
    "                        if 'volume_lag_1' not in train_features and 'close_max_3_days' not in train_features:\n",
    "                            continue                    \n",
    "    #                 elif company == 'meta':\n",
    "    #                     pass \n",
    "    #                 if not ('volume_lag_1' in train_features or 'month' in train_features): continue                    \n",
    "                    elif company == 'netflix':\n",
    "                        if 'close_max_3_days' not in train_features and 'month' not in train_features:\n",
    "                            continue\n",
    "\n",
    "                    config = {\n",
    "                        'unique_uuid': str(uuid.uuid1()),\n",
    "#                         'train_start': train_start,\n",
    "                        'train_end': train_end,\n",
    "                        'test_start': test_start,\n",
    "                        'test_end': test_end,\n",
    "                        'duration_training_history': duration,\n",
    "                        'target_column': 'growth',\n",
    "                        'train_features': train_features,\n",
    "                        'path_to_result': f'/diploma_info/datalake/',\n",
    "                        'forecast_periods': forecast_steps,\n",
    "        #                 'hour_mean_value': 5,\n",
    "                        'model_name': md,\n",
    "                        'model': model,\n",
    "                        'forecast_frequency': period,\n",
    "                        'company': company,\n",
    "                        'model_hyperparameters': hp,\n",
    "                        'problem': problem\n",
    "                    }\n",
    "\n",
    "                    list_of_configs.append(config.copy())\n",
    "    \n",
    "    return list_of_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de80c2e",
   "metadata": {},
   "source": [
    "#### functions used in wfv service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4016f075",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def data(day, X_full_set, y_full_set, train_start, config, forecast_steps):\n",
    "\n",
    "    X_train = X_full_set.loc[train_start:config[\"train_end\"]]\n",
    "    X_test = X_full_set.loc[config[\"test_start\"]+timedelta(days=day):\n",
    "                    config[\"test_start\"]+timedelta(days=day+forecast_steps)]\n",
    "    y_train = y_full_set.loc[train_start:config[\"train_end\"]]\n",
    "    y_test = y_full_set.loc[config[\"test_start\"]+timedelta(days=day):\n",
    "                    config[\"test_start\"]+timedelta(days=day+forecast_steps)]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e1c8fa3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def standardize_mean_values(day, df_test, df_train, config):\n",
    "    \n",
    "    agg_cols = ['close_lag_1', 'volume_lag_1'] + [col for col in config['train_features'] if \"close_m\" in col]\n",
    "    \n",
    "    for agg in agg_cols:\n",
    "        if agg in df_test.columns:\n",
    "            try:\n",
    "                num = df_test.loc[config[\"test_start\"]+timedelta(days=day), agg]\n",
    "\n",
    "            except KeyError as e:\n",
    "                num = df_train[agg].iloc[-1]\n",
    "\n",
    "            finally:\n",
    "\n",
    "                _df = df_test.loc[config[\"test_start\"]+timedelta(days=day):, agg]\n",
    "                _df = _df.replace(_df.values, num)\n",
    "\n",
    "#                 print(df_test.loc[config[\"test_start\"]+timedelta(days=day):, agg], _df.values.ravel())\n",
    "\n",
    "                df_test.loc[config[\"test_start\"]:, agg] = _df.values.ravel()\n",
    "    \n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bc649df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions(day, model_name, df_preds, y_pred_df, y_test, config):\n",
    "    \n",
    "    dates = y_test.index\n",
    "    \n",
    "    for date in dates:\n",
    "        step_day = int((date-(config[\"test_start\"]+timedelta(days=day))).days)\n",
    "        df_preds.loc[date.strftime(\"%Y-%m-%d\"), f'd-{step_day}'] = y_pred_df.loc[date.strftime(\"%Y-%m-%d\"), 0]\n",
    "    \n",
    "    return df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf71e08e",
   "metadata": {
    "code_folding": [
     15,
     20
    ]
   },
   "outputs": [],
   "source": [
    "def estimations(day, df_stats, y_pred_df, y_test, config):\n",
    "    \n",
    "    dates = y_test.index\n",
    "    \n",
    "    for date in dates:\n",
    "        step_day = int((date-(config[\"test_start\"]+timedelta(days=day))).days)\n",
    "\n",
    "        try:\n",
    "            pred = y_pred_df.loc[date].values[0]\n",
    "            real = y_test.loc[date].values[0]\n",
    "\n",
    "            err = pred-real\n",
    "\n",
    "            df_stats.loc[date, f'd-{step_day}' + '_is_true'] = 1 if (err == 0) else 0\n",
    "            \n",
    "        except ZeroDivisionError as e:\n",
    "            print(e)\n",
    "\n",
    "            df_stats.loc[date, f'd-{step_day}' + '_is_true'] = 0\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "\n",
    "            df_stats.loc[date, f'd-{step_day}' + '_is_true'] = 0\n",
    "    \n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "664c8058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(forecast_steps, df_preds, config, research_task_uuid, problem):\n",
    "    \n",
    "    for step in range(forecast_steps+1):\n",
    "        try:\n",
    "            pred = df_preds.loc[:, [f'd-{step}']].dropna().sort_index()\n",
    "            pred.index.name = 'date_time'\n",
    "\n",
    "            path_to_files = os.path.join(config['path_to_result'], \"forecast\", problem,\n",
    "                                         config['company'], config['forecast_frequency'], config['model_name'], \n",
    "                                         f\"research_task_{research_task_uuid}\", \n",
    "                                         f\"{config['model_name']}_{config['unique_uuid']}\")\n",
    "            if not os.path.isdir(path_to_files):\n",
    "                os.makedirs(path_to_files)\n",
    "                \n",
    "            file_name = os.path.join(path_to_files, \n",
    "                    f\"forecast_d-{step}_{config['model_name']}.csv\")\n",
    "\n",
    "            pd.DataFrame(pred).to_csv(file_name)\n",
    "\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41fc750",
   "metadata": {},
   "source": [
    "### wfv service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25651890",
   "metadata": {},
   "source": [
    "#### *add train_features grid (day_means, date_features, lag_features etc.)\n",
    "\n",
    "#### *add checking LightGBM, Random_Forest, Linear_Classifier etc. \n",
    "\n",
    "#### *add lag_features (? check whats better: those or \"mean\"s) \n",
    "\n",
    "#### *am I able to add some factors like inflation/company's profit etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c32598ef",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_wfv(full_set: pd.DataFrame, config: dict, research_task_uuid: str, forecast_steps: int, company: str, models_dict: dict, problem: str):\n",
    "    \n",
    "    X_full_set = full_set.loc[:, config['train_features']]\n",
    "    y_full_set = full_set.loc[:, [config['target_column']]]\n",
    "    \n",
    "    if X_full_set.shape[0] != y_full_set.shape[0]:\n",
    "        common_index = list(set(X_full_set.index) & set(y_full_set.index))\n",
    "        common_index.sort()\n",
    "        X_full_set = X_full_set.loc[common_index, :]\n",
    "        y_full_set = y_full_set.loc[common_index, :]\n",
    "    print(X_full_set.shape, y_full_set.shape)\n",
    "    \n",
    "\n",
    "    df_preds = pd.DataFrame()\n",
    "    df_stats = pd.DataFrame()\n",
    "\n",
    "    count_days = (test_end - test_start).days + 1\n",
    "    \n",
    "    \n",
    "    model_name = config['model_name']\n",
    "    print(model_name)\n",
    "    \n",
    "    model = config['model']\n",
    "\n",
    "    unique_uuid = config['unique_uuid']\n",
    "    \n",
    "    if not os.path.isdir(config['path_to_result']):\n",
    "        os.makedirs(config['path_to_result'])\n",
    "\n",
    "    path_folder_result = os.path.join(config['path_to_result'], \"wf_result\", problem, config['company'], \n",
    "                                      config['forecast_frequency'], model_name,\n",
    "                                      f\"research_task_{research_task_uuid}\")\n",
    "    if not os.path.isdir(path_folder_result):\n",
    "        os.makedirs(path_folder_result)\n",
    "        \n",
    "        \n",
    "\n",
    "    for day in tqdm(range(count_days)):\n",
    "        \n",
    "        train_start = config.get('train_start', None)\n",
    "        if train_start is None:\n",
    "            if config.get('duration_training_history', None) is None:\n",
    "                train_start = X_full_set.index[0]\n",
    "                config['train_start'] = datetime(train_start.year, train_start.month, train_start.day)\n",
    "            else:\n",
    "                train_start = config['train_end'] + timedelta(days=day - config['duration_training_history'])\n",
    "\n",
    "        try:\n",
    "\n",
    "            X_train, X_test, y_train, y_test = data(day, X_full_set, y_full_set, train_start, config, forecast_steps)\n",
    "    #         print(X_train, y_train)\n",
    "            X_test = standardize_mean_values(day, X_test.copy(), X_train, config)\n",
    "    #             print(test_start+timedelta(days=day), 'x_test: ', X_test.head(2))\n",
    "\n",
    "            y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "    #             print(y_pred)\n",
    "\n",
    "            y_pred_df = pd.DataFrame(y_pred, index=y_test.index)\n",
    "            df_preds = add_predictions(day, model_name, df_preds, y_pred_df, y_test, config)\n",
    "\n",
    "            df_stats = estimations(day, df_stats, y_pred_df, y_test, config)\n",
    "        \n",
    "\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "\n",
    "    write_predictions(forecast_steps, df_preds, config, research_task_uuid, problem)\n",
    "\n",
    "\n",
    "    last_index = df_stats.index[-1]\n",
    "    df_stats.loc[last_index, 'model_hyperparameters'] = str(config['model_hyperparameters'])\n",
    "    df_stats.loc[last_index, 'train_features'] = str(config['train_features'])\n",
    "    \n",
    "    path_to_save_result_csv = os.path.join(path_folder_result, f'{model_name}_{unique_uuid}.csv')\n",
    "    df_stats.round(2).to_csv(path_to_save_result_csv, date_format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    config_to_save = config.copy()\n",
    "    config_to_save.pop('model', None)\n",
    "    with open(os.path.join(path_folder_result, f'{model_name}_{unique_uuid}.yaml'), 'w') as outfile:\n",
    "        dump(config_to_save, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0650674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company: AMAZON\t period: daily\t train ends: 2023-12-29 00:00:00\t test starts: 2024-01-02 00:00:00\n",
      "_research_task_uuid = 9efa6436-00a7-11ef-968d-c0e434d84b22\n",
      "\n",
      "count_configs 4 \n",
      "\n",
      "xgboost == {'unique_uuid': '9efa6437-00a7-11ef-bb2f-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'xgboost', 'model': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "              eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=10, n_jobs=-1,\n",
      "              num_parallel_tree=None, ...), 'forecast_frequency': 'daily', 'company': 'amazon', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 4) (2306, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm == {'unique_uuid': '9efa8b4b-00a7-11ef-b17e-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'lightgbm', 'model': LGBMClassifier(eta=0.3, max_depth=7, metric='binary', n_estimators=200,\n",
      "               n_jobs=-1, objective='binary', random_state=2, verbosity=-1), 'forecast_frequency': 'daily', 'company': 'amazon', 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'random_state': 2, 'objective': 'binary', 'verbosity': -1, 'metric': 'binary'}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 4) (2306, 1)\n",
      "lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 37.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest == {'unique_uuid': '9efa8b4c-00a7-11ef-b2f5-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'random_forest', 'model': RandomForestClassifier(max_depth=7, n_estimators=5000, n_jobs=-1,\n",
      "                       random_state=2), 'forecast_frequency': 'daily', 'company': 'amazon', 'model_hyperparameters': {'n_estimators': 5000, 'n_jobs': -1, 'random_state': 2, 'max_depth': 7}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 4) (2306, 1)\n",
      "random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [05:07<00:00,  8.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knear_neighbors == {'unique_uuid': '9efa8b4d-00a7-11ef-8b59-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'knear_neighbors', 'model': KNeighborsClassifier(n_jobs=-1, n_neighbors=50), 'forecast_frequency': 'daily', 'company': 'amazon', 'model_hyperparameters': {'n_neighbors': 50, 'n_jobs': -1}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 4) (2306, 1)\n",
      "knear_neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 64.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 49, n_samples = 5\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 48, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 48, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 48, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 47, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 46, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 45, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 44, n_samples = 5\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 43, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 43, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 43, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 42, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 41, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 40, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 39, n_samples = 5\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 38, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 38, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 38, n_samples = 3\n",
      "company: APPLE\t period: daily\t train ends: 2023-12-29 00:00:00\t test starts: 2024-01-02 00:00:00\n",
      "_research_task_uuid = 57e3c267-00a8-11ef-9426-c0e434d84b22\n",
      "\n",
      "count_configs 9 \n",
      "\n",
      "xgboost == {'unique_uuid': '57e3c268-00a8-11ef-9d2c-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'xgboost', 'model': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "              eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=10, n_jobs=-1,\n",
      "              num_parallel_tree=None, ...), 'forecast_frequency': 'daily', 'company': 'apple', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 53.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': '57e3c269-00a8-11ef-9fb2-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'xgboost', 'model': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "              eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "              num_parallel_tree=None, ...), 'forecast_frequency': 'daily', 'company': 'apple', 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 19.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': '57e3c26a-00a8-11ef-90e5-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'xgboost', 'model': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "              eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=10, n_jobs=-1,\n",
      "              num_parallel_tree=None, ...), 'forecast_frequency': 'daily', 'company': 'apple', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 52.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': '57e3c26b-00a8-11ef-a564-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'xgboost', 'model': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "              eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "              num_parallel_tree=None, ...), 'forecast_frequency': 'daily', 'company': 'apple', 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:02<00:00, 18.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm == {'unique_uuid': '57e3c26c-00a8-11ef-8e12-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'lightgbm', 'model': LGBMClassifier(eta=0.3, max_depth=7, metric='binary', n_estimators=5000,\n",
      "               n_jobs=-1, objective='binary', random_state=2, verbosity=-1), 'forecast_frequency': 'daily', 'company': 'apple', 'model_hyperparameters': {'n_estimators': 5000, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'random_state': 2, 'objective': 'binary', 'verbosity': -1, 'metric': 'binary'}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:11<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm == {'unique_uuid': '57e3c26d-00a8-11ef-b87a-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'lightgbm', 'model': LGBMClassifier(eta=0.3, max_depth=9, metric='binary', n_estimators=5000,\n",
      "               n_jobs=-1, objective='binary', random_state=2, verbosity=-1), 'forecast_frequency': 'daily', 'company': 'apple', 'model_hyperparameters': {'n_estimators': 5000, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'random_state': 2, 'objective': 'binary', 'verbosity': -1, 'metric': 'binary'}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:11<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest == {'unique_uuid': '57e3c26e-00a8-11ef-92cf-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'random_forest', 'model': RandomForestClassifier(max_depth=7, n_estimators=10, n_jobs=-1, random_state=2), 'forecast_frequency': 'daily', 'company': 'apple', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'random_state': 2, 'max_depth': 7}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:02<00:00, 15.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knear_neighbors == {'unique_uuid': '57e3c26f-00a8-11ef-a43a-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'knear_neighbors', 'model': KNeighborsClassifier(n_jobs=-1, n_neighbors=3), 'forecast_frequency': 'daily', 'company': 'apple', 'model_hyperparameters': {'n_neighbors': 3, 'n_jobs': -1}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "knear_neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 33.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knear_neighbors == {'unique_uuid': '57e3c270-00a8-11ef-8f71-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'knear_neighbors', 'model': KNeighborsClassifier(n_jobs=-1, n_neighbors=50), 'forecast_frequency': 'daily', 'company': 'apple', 'model_hyperparameters': {'n_neighbors': 50, 'n_jobs': -1}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "knear_neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 125.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 49, n_samples = 5\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 48, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 48, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 48, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 47, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 46, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 45, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 44, n_samples = 5\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 43, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 43, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 43, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 42, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 41, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 40, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 39, n_samples = 5\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 38, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 38, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 38, n_samples = 3\n",
      "company: GOOGLE\t period: daily\t train ends: 2023-12-29 00:00:00\t test starts: 2024-01-02 00:00:00\n",
      "_research_task_uuid = 6afd1e08-00a8-11ef-8fe8-c0e434d84b22\n",
      "\n",
      "count_configs 10 \n",
      "\n",
      "xgboost == {'unique_uuid': '6afd1e09-00a8-11ef-8374-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'xgboost', 'model': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "              eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=10, n_jobs=-1,\n",
      "              num_parallel_tree=None, ...), 'forecast_frequency': 'daily', 'company': 'google', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 53.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': '6afd1e0a-00a8-11ef-aa25-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'xgboost', 'model': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "              eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "              num_parallel_tree=None, ...), 'forecast_frequency': 'daily', 'company': 'google', 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 19.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': '6afd1e0b-00a8-11ef-b72c-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'xgboost', 'model': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "              eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=10, n_jobs=-1,\n",
      "              num_parallel_tree=None, ...), 'forecast_frequency': 'daily', 'company': 'google', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 52.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': '6afd1e0c-00a8-11ef-b30a-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'xgboost', 'model': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "              eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "              num_parallel_tree=None, ...), 'forecast_frequency': 'daily', 'company': 'google', 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:02<00:00, 18.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm == {'unique_uuid': '6afd1e0d-00a8-11ef-b011-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'lightgbm', 'model': LGBMClassifier(eta=0.3, max_depth=7, metric='binary', n_estimators=10,\n",
      "               n_jobs=-1, objective='binary', random_state=2, verbosity=-1), 'forecast_frequency': 'daily', 'company': 'google', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'random_state': 2, 'objective': 'binary', 'verbosity': -1, 'metric': 'binary'}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 69.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm == {'unique_uuid': '6afd1e0e-00a8-11ef-9c8b-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'lightgbm', 'model': LGBMClassifier(eta=0.3, max_depth=9, metric='binary', n_estimators=10,\n",
      "               n_jobs=-1, objective='binary', random_state=2, verbosity=-1), 'forecast_frequency': 'daily', 'company': 'google', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'random_state': 2, 'objective': 'binary', 'verbosity': -1, 'metric': 'binary'}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 67.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest == {'unique_uuid': '6afd1e0f-00a8-11ef-b957-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'random_forest', 'model': RandomForestClassifier(max_depth=9, n_estimators=10, n_jobs=-1, random_state=2), 'forecast_frequency': 'daily', 'company': 'google', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'random_state': 2, 'max_depth': 9}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:02<00:00, 15.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest == {'unique_uuid': '6afd1e10-00a8-11ef-b2db-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'random_forest', 'model': RandomForestClassifier(max_depth=9, n_estimators=200, n_jobs=-1, random_state=2), 'forecast_frequency': 'daily', 'company': 'google', 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'random_state': 2, 'max_depth': 9}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:13<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knear_neighbors == {'unique_uuid': '6afd1e11-00a8-11ef-ba4a-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'knear_neighbors', 'model': KNeighborsClassifier(n_jobs=-1, n_neighbors=3), 'forecast_frequency': 'daily', 'company': 'google', 'model_hyperparameters': {'n_neighbors': 3, 'n_jobs': -1}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "knear_neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 34.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knear_neighbors == {'unique_uuid': '6afd1e12-00a8-11ef-90e2-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'knear_neighbors', 'model': KNeighborsClassifier(n_jobs=-1), 'forecast_frequency': 'daily', 'company': 'google', 'model_hyperparameters': {'n_neighbors': 5, 'n_jobs': -1}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "knear_neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 34.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company: META\t period: daily\t train ends: 2023-12-29 00:00:00\t test starts: 2024-01-02 00:00:00\n",
      "_research_task_uuid = 7a2a86e8-00a8-11ef-af0f-c0e434d84b22\n",
      "\n",
      "count_configs 15 \n",
      "\n",
      "xgboost == {'unique_uuid': '7a2a86e9-00a8-11ef-b3a4-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'volume_mixed'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'xgboost', 'model': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "              eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=5000, n_jobs=-1,\n",
      "              num_parallel_tree=None, ...), 'forecast_frequency': 'daily', 'company': 'meta', 'model_hyperparameters': {'n_estimators': 5000, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 2) (2306, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:23<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': '7a2a86ea-00a8-11ef-b73b-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'xgboost', 'model': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "              eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=5000, n_jobs=-1,\n",
      "              num_parallel_tree=None, ...), 'forecast_frequency': 'daily', 'company': 'meta', 'model_hyperparameters': {'n_estimators': 5000, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 4) (2306, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:25<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': '7a2a86eb-00a8-11ef-a014-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'xgboost', 'model': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "              eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=5000, n_jobs=-1,\n",
      "              num_parallel_tree=None, ...), 'forecast_frequency': 'daily', 'company': 'meta', 'model_hyperparameters': {'n_estimators': 5000, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:30<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm == {'unique_uuid': '7a2a86ec-00a8-11ef-889f-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'volume_mixed'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'lightgbm', 'model': LGBMClassifier(eta=0.3, max_depth=7, metric='binary', n_estimators=5000,\n",
      "               n_jobs=-1, objective='binary', random_state=2, verbosity=-1), 'forecast_frequency': 'daily', 'company': 'meta', 'model_hyperparameters': {'n_estimators': 5000, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'random_state': 2, 'objective': 'binary', 'verbosity': -1, 'metric': 'binary'}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 2) (2306, 1)\n",
      "lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:13<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm == {'unique_uuid': '7a2a86ed-00a8-11ef-8e65-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'lightgbm', 'model': LGBMClassifier(eta=0.3, max_depth=7, metric='binary', n_estimators=5000,\n",
      "               n_jobs=-1, objective='binary', random_state=2, verbosity=-1), 'forecast_frequency': 'daily', 'company': 'meta', 'model_hyperparameters': {'n_estimators': 5000, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'random_state': 2, 'objective': 'binary', 'verbosity': -1, 'metric': 'binary'}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 4) (2306, 1)\n",
      "lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:13<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm == {'unique_uuid': '7a2a86ee-00a8-11ef-8375-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'lightgbm', 'model': LGBMClassifier(eta=0.3, max_depth=7, metric='binary', n_estimators=5000,\n",
      "               n_jobs=-1, objective='binary', random_state=2, verbosity=-1), 'forecast_frequency': 'daily', 'company': 'meta', 'model_hyperparameters': {'n_estimators': 5000, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'random_state': 2, 'objective': 'binary', 'verbosity': -1, 'metric': 'binary'}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:12<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm == {'unique_uuid': '7a2a86ef-00a8-11ef-b850-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'volume_mixed'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'lightgbm', 'model': LGBMClassifier(eta=0.3, max_depth=9, metric='binary', n_estimators=5000,\n",
      "               n_jobs=-1, objective='binary', random_state=2, verbosity=-1), 'forecast_frequency': 'daily', 'company': 'meta', 'model_hyperparameters': {'n_estimators': 5000, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'random_state': 2, 'objective': 'binary', 'verbosity': -1, 'metric': 'binary'}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 2) (2306, 1)\n",
      "lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:12<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm == {'unique_uuid': '7a2a86f0-00a8-11ef-847b-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'lightgbm', 'model': LGBMClassifier(eta=0.3, max_depth=9, metric='binary', n_estimators=5000,\n",
      "               n_jobs=-1, objective='binary', random_state=2, verbosity=-1), 'forecast_frequency': 'daily', 'company': 'meta', 'model_hyperparameters': {'n_estimators': 5000, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'random_state': 2, 'objective': 'binary', 'verbosity': -1, 'metric': 'binary'}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 4) (2306, 1)\n",
      "lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:13<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm == {'unique_uuid': '7a2a86f1-00a8-11ef-8bc4-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'lightgbm', 'model': LGBMClassifier(eta=0.3, max_depth=9, metric='binary', n_estimators=5000,\n",
      "               n_jobs=-1, objective='binary', random_state=2, verbosity=-1), 'forecast_frequency': 'daily', 'company': 'meta', 'model_hyperparameters': {'n_estimators': 5000, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'random_state': 2, 'objective': 'binary', 'verbosity': -1, 'metric': 'binary'}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:12<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest == {'unique_uuid': '7a2a86f2-00a8-11ef-8a17-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'volume_mixed'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'random_forest', 'model': RandomForestClassifier(max_depth=9, n_estimators=10, n_jobs=-1, random_state=2), 'forecast_frequency': 'daily', 'company': 'meta', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'random_state': 2, 'max_depth': 9}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 2) (2306, 1)\n",
      "random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:02<00:00, 15.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest == {'unique_uuid': '7a2a86f3-00a8-11ef-8774-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'random_forest', 'model': RandomForestClassifier(max_depth=9, n_estimators=10, n_jobs=-1, random_state=2), 'forecast_frequency': 'daily', 'company': 'meta', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'random_state': 2, 'max_depth': 9}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 4) (2306, 1)\n",
      "random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:02<00:00, 14.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest == {'unique_uuid': '7a2a86f4-00a8-11ef-9ab6-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'random_forest', 'model': RandomForestClassifier(max_depth=9, n_estimators=10, n_jobs=-1, random_state=2), 'forecast_frequency': 'daily', 'company': 'meta', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'random_state': 2, 'max_depth': 9}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:02<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knear_neighbors == {'unique_uuid': '7a2a86f5-00a8-11ef-a644-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'volume_mixed'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'knear_neighbors', 'model': KNeighborsClassifier(n_jobs=-1, n_neighbors=9), 'forecast_frequency': 'daily', 'company': 'meta', 'model_hyperparameters': {'n_neighbors': 9, 'n_jobs': -1}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 2) (2306, 1)\n",
      "knear_neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 34.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knear_neighbors == {'unique_uuid': '7a2a86f6-00a8-11ef-956d-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'knear_neighbors', 'model': KNeighborsClassifier(n_jobs=-1, n_neighbors=9), 'forecast_frequency': 'daily', 'company': 'meta', 'model_hyperparameters': {'n_neighbors': 9, 'n_jobs': -1}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 4) (2306, 1)\n",
      "knear_neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 30.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knear_neighbors == {'unique_uuid': '7a2a86f7-00a8-11ef-a97e-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'knear_neighbors', 'model': KNeighborsClassifier(n_jobs=-1, n_neighbors=9), 'forecast_frequency': 'daily', 'company': 'meta', 'model_hyperparameters': {'n_neighbors': 9, 'n_jobs': -1}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "knear_neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 34.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company: NETFLIX\t period: daily\t train ends: 2023-12-29 00:00:00\t test starts: 2024-01-02 00:00:00\n",
      "_research_task_uuid = dfc52a97-00a8-11ef-867c-c0e434d84b22\n",
      "\n",
      "count_configs 12 \n",
      "\n",
      "xgboost == {'unique_uuid': 'dfc52a98-00a8-11ef-b9e5-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'xgboost', 'model': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "              eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "              num_parallel_tree=None, ...), 'forecast_frequency': 'daily', 'company': 'netflix', 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 4) (2306, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:02<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'dfc52a99-00a8-11ef-a441-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'xgboost', 'model': XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "              eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "              num_parallel_tree=None, ...), 'forecast_frequency': 'daily', 'company': 'netflix', 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:02<00:00, 17.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm == {'unique_uuid': 'dfc52a9a-00a8-11ef-b4a5-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'lightgbm', 'model': LGBMClassifier(eta=0.3, max_depth=9, metric='binary', n_estimators=10,\n",
      "               n_jobs=-1, objective='binary', random_state=2, verbosity=-1), 'forecast_frequency': 'daily', 'company': 'netflix', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'random_state': 2, 'objective': 'binary', 'verbosity': -1, 'metric': 'binary'}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 4) (2306, 1)\n",
      "lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 51.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm == {'unique_uuid': 'dfc52a9b-00a8-11ef-b52d-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'lightgbm', 'model': LGBMClassifier(eta=0.3, max_depth=9, metric='binary', n_estimators=10,\n",
      "               n_jobs=-1, objective='binary', random_state=2, verbosity=-1), 'forecast_frequency': 'daily', 'company': 'netflix', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'random_state': 2, 'objective': 'binary', 'verbosity': -1, 'metric': 'binary'}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 63.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm == {'unique_uuid': 'dfc52a9c-00a8-11ef-b3ed-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'lightgbm', 'model': LGBMClassifier(eta=0.3, max_depth=9, metric='binary', n_estimators=5000,\n",
      "               n_jobs=-1, objective='binary', random_state=2, verbosity=-1), 'forecast_frequency': 'daily', 'company': 'netflix', 'model_hyperparameters': {'n_estimators': 5000, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'random_state': 2, 'objective': 'binary', 'verbosity': -1, 'metric': 'binary'}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 4) (2306, 1)\n",
      "lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:12<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm == {'unique_uuid': 'dfc52a9d-00a8-11ef-862e-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'lightgbm', 'model': LGBMClassifier(eta=0.3, max_depth=9, metric='binary', n_estimators=5000,\n",
      "               n_jobs=-1, objective='binary', random_state=2, verbosity=-1), 'forecast_frequency': 'daily', 'company': 'netflix', 'model_hyperparameters': {'n_estimators': 5000, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'random_state': 2, 'objective': 'binary', 'verbosity': -1, 'metric': 'binary'}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:12<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest == {'unique_uuid': 'dfc52a9e-00a8-11ef-a878-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'random_forest', 'model': RandomForestClassifier(max_depth=7, n_estimators=10, n_jobs=-1, random_state=2), 'forecast_frequency': 'daily', 'company': 'netflix', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'random_state': 2, 'max_depth': 7}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 4) (2306, 1)\n",
      "random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:02<00:00, 14.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest == {'unique_uuid': 'dfc52a9f-00a8-11ef-9036-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'random_forest', 'model': RandomForestClassifier(max_depth=7, n_estimators=10, n_jobs=-1, random_state=2), 'forecast_frequency': 'daily', 'company': 'netflix', 'model_hyperparameters': {'n_estimators': 10, 'n_jobs': -1, 'random_state': 2, 'max_depth': 7}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:02<00:00, 15.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knear_neighbors == {'unique_uuid': 'dfc52aa0-00a8-11ef-b4df-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'knear_neighbors', 'model': KNeighborsClassifier(n_jobs=-1, n_neighbors=3), 'forecast_frequency': 'daily', 'company': 'netflix', 'model_hyperparameters': {'n_neighbors': 3, 'n_jobs': -1}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 4) (2306, 1)\n",
      "knear_neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knear_neighbors == {'unique_uuid': 'dfc52aa1-00a8-11ef-8ec7-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'knear_neighbors', 'model': KNeighborsClassifier(n_jobs=-1, n_neighbors=3), 'forecast_frequency': 'daily', 'company': 'netflix', 'model_hyperparameters': {'n_neighbors': 3, 'n_jobs': -1}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "knear_neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 36.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knear_neighbors == {'unique_uuid': 'dfc52aa2-00a8-11ef-90de-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'close_max_3_days', 'close_min_3_days', 'close_mean_3_days'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'knear_neighbors', 'model': KNeighborsClassifier(n_jobs=-1, n_neighbors=50), 'forecast_frequency': 'daily', 'company': 'netflix', 'model_hyperparameters': {'n_neighbors': 50, 'n_jobs': -1}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 4) (2306, 1)\n",
      "knear_neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 96.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 49, n_samples = 5\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 48, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 48, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 48, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 47, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 46, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 45, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 44, n_samples = 5\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 43, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 43, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 43, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 42, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 41, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 40, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 39, n_samples = 5\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 38, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 38, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 38, n_samples = 3\n",
      "knear_neighbors == {'unique_uuid': 'dfc52aa3-00a8-11ef-a1f8-c0e434d84b22', 'train_end': datetime.datetime(2023, 12, 29, 0, 0), 'test_start': datetime.datetime(2024, 1, 2, 0, 0), 'test_end': datetime.datetime(2024, 2, 8, 0, 0), 'duration_training_history': 90, 'target_column': 'growth', 'train_features': ['close_mixed', 'year', 'month', 'day', 'day_of_week', 'week_of_year'], 'path_to_result': '/diploma_info/datalake/', 'forecast_periods': 4, 'model_name': 'knear_neighbors', 'model': KNeighborsClassifier(n_jobs=-1, n_neighbors=50), 'forecast_frequency': 'daily', 'company': 'netflix', 'model_hyperparameters': {'n_neighbors': 50, 'n_jobs': -1}, 'problem': 'classification'} \n",
      "\n",
      "(2306, 6) (2306, 1)\n",
      "knear_neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 126.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 49, n_samples = 5\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 48, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 48, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 48, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 47, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 46, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 45, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 44, n_samples = 5\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 43, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 43, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 43, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 42, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 41, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 40, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 39, n_samples = 5\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 38, n_samples = 4\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 38, n_samples = 3\n",
      "Expected n_neighbors <= n_samples_fit, but n_neighbors = 50, n_samples_fit = 38, n_samples = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# companies = [\"NETFLIX\"]\n",
    "companies = [\"AMAZON\", \"APPLE\", \"GOOGLE\", \"META\", \"NETFLIX\"]\n",
    "time_period = [\"daily\"]\n",
    "# time_period = [\"daily\", \"weekly\", \"monthly\"]\n",
    "\n",
    "problem = 'classification'\n",
    "models_list = ['XGBoost', 'LightGBM', 'Random_Forest', 'KNear_Neighbors']\n",
    "# models_list = ['XGBoost', 'LightGBM', 'Random_Forest', 'KNear_Neighbors', 'LOGistic_REGression']\n",
    "# models_list = ['Prophet']\n",
    "models_dict = dict([(\"\".join(re.findall('([A-Z])', k)).lower(), k.lower()) for k in models_list])\n",
    "\n",
    "forecast_steps = 4        # means that forecast will be made on {n} futute periods \n",
    " \n",
    "\n",
    "for company, period in list(itertools.product(companies, time_period)):\n",
    "    \n",
    "    full_set, train_end, test_start, test_end, train_features_set = init(company, period)\n",
    "    print(f'company: {company}\\t period: {period}\\t train ends: {train_end}\\t test starts: {test_start}')\n",
    "    \n",
    "    _research_task_uuid = str(uuid.uuid1())\n",
    "    print(f'_research_task_uuid = {_research_task_uuid}\\n')\n",
    "    \n",
    "    configs = define_parameters(company.lower(), period.lower(), train_end, test_start, test_end, train_features_set, forecast_steps, models_dict, problem)\n",
    "    print(f'count_configs {len(configs)} \\n')\n",
    "    \n",
    "    for _ in configs:\n",
    "        print(_['model_name'], '==', _, '\\n')\n",
    "        \n",
    "        run_wfv(full_set, _, _research_task_uuid, forecast_steps, company, models_dict, problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf350a9",
   "metadata": {},
   "source": [
    "## View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1cc9fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_preds['true_val'] = df.growth\n",
    "# df_preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "754ad290",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# df_preds[(df_preds['true_val'] - df_preds['xgb_10_3_d-1'])==0]\n",
    "\n",
    "# df_errors = pd.DataFrame()\n",
    "\n",
    "\n",
    "# for d in [0, 1, 2, 3]:\n",
    "#     for n in [k for k in df_preds.columns if f'd-{d}' in k]:\n",
    "#         acc = round(abs(df_preds[(df_preds['true_val'] - df_preds[n])==0].shape[0]/df_preds.shape[0] - 1), 2) * 100\n",
    "        \n",
    "# #         print(n, acc)\n",
    "#         df_errors.loc[d, n.split(\"_d\")[0]] = acc\n",
    "        \n",
    "#     print(df_errors.iloc[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39d4f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_errors[[k for k in df_errors.columns if 'lin' in k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "832db5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>diff_close_value</th>\n",
       "      <th>growth</th>\n",
       "      <th>growth_lag_1</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>close_min_7_days</th>\n",
       "      <th>close_mean_7_days</th>\n",
       "      <th>1_USD_to_EUR_lag_1</th>\n",
       "      <th>1_EUR_to_USD_lag_1</th>\n",
       "      <th>1_UAH_to_USD_lag_1</th>\n",
       "      <th>1_USD_to_UAH_lag_1</th>\n",
       "      <th>1_EUR_to_UAH_lag_1</th>\n",
       "      <th>1_UAH_to_EUR_lag_1</th>\n",
       "      <th>close_mixed</th>\n",
       "      <th>volume_mixed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>49.151428</td>\n",
       "      <td>50.331429</td>\n",
       "      <td>48.731430</td>\n",
       "      <td>49.848572</td>\n",
       "      <td>49.848572</td>\n",
       "      <td>13475000</td>\n",
       "      <td>1.047142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.8265</td>\n",
       "      <td>1.2098</td>\n",
       "      <td>0.06322</td>\n",
       "      <td>15.819</td>\n",
       "      <td>19.138</td>\n",
       "      <td>0.05225</td>\n",
       "      <td>49.848572</td>\n",
       "      <td>13475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>49.258572</td>\n",
       "      <td>49.258572</td>\n",
       "      <td>47.147144</td>\n",
       "      <td>47.311428</td>\n",
       "      <td>47.311428</td>\n",
       "      <td>18165000</td>\n",
       "      <td>-2.537144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.8370</td>\n",
       "      <td>1.1946</td>\n",
       "      <td>0.06265</td>\n",
       "      <td>15.962</td>\n",
       "      <td>18.900</td>\n",
       "      <td>0.05243</td>\n",
       "      <td>47.311428</td>\n",
       "      <td>18165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>47.347141</td>\n",
       "      <td>47.639999</td>\n",
       "      <td>45.661430</td>\n",
       "      <td>46.501431</td>\n",
       "      <td>46.501431</td>\n",
       "      <td>16037700</td>\n",
       "      <td>-0.809998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.8391</td>\n",
       "      <td>1.1918</td>\n",
       "      <td>0.06322</td>\n",
       "      <td>15.818</td>\n",
       "      <td>18.852</td>\n",
       "      <td>0.05305</td>\n",
       "      <td>46.501431</td>\n",
       "      <td>16037700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>47.347141</td>\n",
       "      <td>47.421429</td>\n",
       "      <td>46.271427</td>\n",
       "      <td>46.742859</td>\n",
       "      <td>46.742859</td>\n",
       "      <td>9849700</td>\n",
       "      <td>0.241428</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.8377</td>\n",
       "      <td>1.1937</td>\n",
       "      <td>0.06317</td>\n",
       "      <td>15.830</td>\n",
       "      <td>18.896</td>\n",
       "      <td>0.05292</td>\n",
       "      <td>46.742859</td>\n",
       "      <td>9849700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>47.119999</td>\n",
       "      <td>47.835712</td>\n",
       "      <td>46.478573</td>\n",
       "      <td>47.779999</td>\n",
       "      <td>47.779999</td>\n",
       "      <td>9601900</td>\n",
       "      <td>1.037140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.8461</td>\n",
       "      <td>1.1819</td>\n",
       "      <td>0.06317</td>\n",
       "      <td>15.830</td>\n",
       "      <td>18.709</td>\n",
       "      <td>0.05345</td>\n",
       "      <td>47.779999</td>\n",
       "      <td>9601900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-26</th>\n",
       "      <td>583.559998</td>\n",
       "      <td>590.750000</td>\n",
       "      <td>583.270020</td>\n",
       "      <td>587.650024</td>\n",
       "      <td>587.650024</td>\n",
       "      <td>2393700</td>\n",
       "      <td>4.090027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>...</td>\n",
       "      <td>573.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>1.0832</td>\n",
       "      <td>0.02612</td>\n",
       "      <td>38.283</td>\n",
       "      <td>41.470</td>\n",
       "      <td>0.02411</td>\n",
       "      <td>583.559998</td>\n",
       "      <td>2568900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-27</th>\n",
       "      <td>595.000000</td>\n",
       "      <td>605.359985</td>\n",
       "      <td>592.330017</td>\n",
       "      <td>601.669983</td>\n",
       "      <td>601.669983</td>\n",
       "      <td>4489400</td>\n",
       "      <td>14.019958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>...</td>\n",
       "      <td>573.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>0.9217</td>\n",
       "      <td>1.0849</td>\n",
       "      <td>0.02604</td>\n",
       "      <td>38.397</td>\n",
       "      <td>41.658</td>\n",
       "      <td>0.02401</td>\n",
       "      <td>587.650024</td>\n",
       "      <td>2393700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-28</th>\n",
       "      <td>595.789978</td>\n",
       "      <td>598.169983</td>\n",
       "      <td>590.010010</td>\n",
       "      <td>596.479980</td>\n",
       "      <td>596.479980</td>\n",
       "      <td>2605200</td>\n",
       "      <td>-5.190002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>...</td>\n",
       "      <td>573.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0.9221</td>\n",
       "      <td>1.0844</td>\n",
       "      <td>0.02613</td>\n",
       "      <td>38.270</td>\n",
       "      <td>41.501</td>\n",
       "      <td>0.02410</td>\n",
       "      <td>601.669983</td>\n",
       "      <td>4489400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-29</th>\n",
       "      <td>604.250000</td>\n",
       "      <td>604.520020</td>\n",
       "      <td>595.159973</td>\n",
       "      <td>602.919983</td>\n",
       "      <td>602.919983</td>\n",
       "      <td>3572100</td>\n",
       "      <td>6.440002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>...</td>\n",
       "      <td>573.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>1.0841</td>\n",
       "      <td>0.02626</td>\n",
       "      <td>38.076</td>\n",
       "      <td>41.277</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>596.479980</td>\n",
       "      <td>2605200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-01</th>\n",
       "      <td>599.809998</td>\n",
       "      <td>620.280029</td>\n",
       "      <td>599.500000</td>\n",
       "      <td>619.340027</td>\n",
       "      <td>619.340027</td>\n",
       "      <td>4264200</td>\n",
       "      <td>16.420044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>...</td>\n",
       "      <td>573.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>0.9255</td>\n",
       "      <td>1.0805</td>\n",
       "      <td>0.02629</td>\n",
       "      <td>38.041</td>\n",
       "      <td>41.102</td>\n",
       "      <td>0.02433</td>\n",
       "      <td>602.919983</td>\n",
       "      <td>3572100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2306 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close   adj_close  \\\n",
       "date                                                                     \n",
       "2015-01-02   49.151428   50.331429   48.731430   49.848572   49.848572   \n",
       "2015-01-05   49.258572   49.258572   47.147144   47.311428   47.311428   \n",
       "2015-01-06   47.347141   47.639999   45.661430   46.501431   46.501431   \n",
       "2015-01-07   47.347141   47.421429   46.271427   46.742859   46.742859   \n",
       "2015-01-08   47.119999   47.835712   46.478573   47.779999   47.779999   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2024-02-26  583.559998  590.750000  583.270020  587.650024  587.650024   \n",
       "2024-02-27  595.000000  605.359985  592.330017  601.669983  601.669983   \n",
       "2024-02-28  595.789978  598.169983  590.010010  596.479980  596.479980   \n",
       "2024-02-29  604.250000  604.520020  595.159973  602.919983  602.919983   \n",
       "2024-03-01  599.809998  620.280029  599.500000  619.340027  619.340027   \n",
       "\n",
       "              volume  diff_close_value  growth  growth_lag_1  year  ...  \\\n",
       "date                                                                ...   \n",
       "2015-01-02  13475000          1.047142     1.0           0.0  2015  ...   \n",
       "2015-01-05  18165000         -2.537144     0.0           1.0  2015  ...   \n",
       "2015-01-06  16037700         -0.809998     0.0           0.0  2015  ...   \n",
       "2015-01-07   9849700          0.241428     1.0           0.0  2015  ...   \n",
       "2015-01-08   9601900          1.037140     1.0           1.0  2015  ...   \n",
       "...              ...               ...     ...           ...   ...  ...   \n",
       "2024-02-26   2393700          4.090027     1.0           0.0  2024  ...   \n",
       "2024-02-27   4489400         14.019958     1.0           1.0  2024  ...   \n",
       "2024-02-28   2605200         -5.190002     0.0           1.0  2024  ...   \n",
       "2024-02-29   3572100          6.440002     1.0           0.0  2024  ...   \n",
       "2024-03-01   4264200         16.420044     1.0           1.0  2024  ...   \n",
       "\n",
       "            close_min_7_days  close_mean_7_days  1_USD_to_EUR_lag_1  \\\n",
       "date                                                                  \n",
       "2015-01-02              48.0               49.0              0.8265   \n",
       "2015-01-05              48.0               49.0              0.8370   \n",
       "2015-01-06              47.0               49.0              0.8391   \n",
       "2015-01-07              47.0               48.0              0.8377   \n",
       "2015-01-08              47.0               48.0              0.8461   \n",
       "...                      ...                ...                 ...   \n",
       "2024-02-26             573.0              582.0              0.9232   \n",
       "2024-02-27             573.0              584.0              0.9217   \n",
       "2024-02-28             573.0              585.0              0.9221   \n",
       "2024-02-29             573.0              587.0              0.9225   \n",
       "2024-03-01             573.0              591.0              0.9255   \n",
       "\n",
       "            1_EUR_to_USD_lag_1  1_UAH_to_USD_lag_1  1_USD_to_UAH_lag_1  \\\n",
       "date                                                                     \n",
       "2015-01-02              1.2098             0.06322              15.819   \n",
       "2015-01-05              1.1946             0.06265              15.962   \n",
       "2015-01-06              1.1918             0.06322              15.818   \n",
       "2015-01-07              1.1937             0.06317              15.830   \n",
       "2015-01-08              1.1819             0.06317              15.830   \n",
       "...                        ...                 ...                 ...   \n",
       "2024-02-26              1.0832             0.02612              38.283   \n",
       "2024-02-27              1.0849             0.02604              38.397   \n",
       "2024-02-28              1.0844             0.02613              38.270   \n",
       "2024-02-29              1.0841             0.02626              38.076   \n",
       "2024-03-01              1.0805             0.02629              38.041   \n",
       "\n",
       "            1_EUR_to_UAH_lag_1  1_UAH_to_EUR_lag_1  close_mixed  volume_mixed  \n",
       "date                                                                           \n",
       "2015-01-02              19.138             0.05225    49.848572      13475000  \n",
       "2015-01-05              18.900             0.05243    47.311428      18165000  \n",
       "2015-01-06              18.852             0.05305    46.501431      16037700  \n",
       "2015-01-07              18.896             0.05292    46.742859       9849700  \n",
       "2015-01-08              18.709             0.05345    47.779999       9601900  \n",
       "...                        ...                 ...          ...           ...  \n",
       "2024-02-26              41.470             0.02411   583.559998       2568900  \n",
       "2024-02-27              41.658             0.02401   587.650024       2393700  \n",
       "2024-02-28              41.501             0.02410   601.669983       4489400  \n",
       "2024-02-29              41.277             0.02423   596.479980       2605200  \n",
       "2024-03-01              41.102             0.02433   602.919983       3572100  \n",
       "\n",
       "[2306 rows x 52 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
